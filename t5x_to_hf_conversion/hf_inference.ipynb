{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea869e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "\n",
    "from transformers import T5ForConditionalGeneration, PreTrainedTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c6c5d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = 'config.json'\n",
    "pytorch_model_path = 'converted_pt_model'\n",
    "model = T5ForConditionalGeneration.from_pretrained(pytorch_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6295bd3-b3fd-43ac-9ddc-699dd82f53f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,141,824,512\n"
     ]
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'{pytorch_total_params:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a721d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "<extra_id_98>\n",
      "<extra_id_97>\n",
      "<extra_id_96>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/meliksah.turker/.pyenv/versions/3.10.13/lib/python3.10/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11070). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "tokenizer = PreTrainedTokenizerFast.from_pretrained('VBARTTokenizer_T5_Sentinels')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Device: {device}')\n",
    "\n",
    "# Test tokenizer's sentinel tokens\n",
    "for i in range(32001, 32004):\n",
    "    print(tokenizer.decode([i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49fa0d7-238c-4818-bc71-b8dc6ff4e50b",
   "metadata": {},
   "source": [
    "- Infer on Onur's Test Dataset **Tokens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49bafb18-c9f2-4714-ad04-88db355b2676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Data\n",
    "json_test_data_path = \"/media/disk/datasets/bounllm/oscarmc4_cleaned_hf_dataset_validation-single_shards_with_encoded_values.json.gz\"\n",
    "gzip_file = gzip.open(json_test_data_path)\n",
    "byte_lines = [line for line in gzip_file]\n",
    "json_lines = [json.loads(byte_line) for byte_line in byte_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5eea15e1-3c2a-4d42-a62d-6f775c846a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NLU] gelmez. Bu açıdan sürekliliği olan bu tip programları devam <extra_id_0> önemlidir. Burada emeği geçenlere teşekkür ediyorum. Yığinki, neticede hepimizin çocukluğunun geçtiği, lahanasından is <extra_id_1>na <extra_id_2> yetiştirdiği insanlara kadar <extra_id_3> kadim bir mahalleden bahsediyoruz. Elazığ'ı Aksaray'sız düşünmek mümkün değil. Bu mahalle <extra_id_4> komşuluk kültüründen öte bir akraba kültürü ile <extra_id_5> insanlardır. Yığ <extra_id_6>ki’yi yeniden anmak <extra_id_7> gelmek, elbette büyük bir mutluluktur” <extra_id_8>. Yapısal, fonksiyonel ve sanatsal özellikleriyle iç ve dış mekanda kullanılan bir mimari şeklidir. Demirin kullanılmasıyla elde edilen ferforjeler, göze hoş gelen ve yapımı ince işçilik isteyen ürünlerdir. Bu konuda hizmet veren firmalar, özellikle nostaljik görüntüden <extra_id_9> iç mimaride tercih edilmektedir. “Ferforje” konusunda iç mimaride ayna çerçevesi, yatak başlığı, şamdanlık, merdiven <extra_id_10>, dış mekanlarda ise bina kapısı, bahçe kapısı, pencere parmaklığı, <extra_id_11> edilmesi gereken en önemli nokta ise <extra_id_12> ihtiyacın belirlenmesi ve bu doğrultuda üretim yapılmasıdır. Günümüzde mimari alanda yaşanan gelişmeler sonucunda “ferforje” son derece önemli bir yer edinmiştir. Sadece ihtiyaç değil görsel anlamda da gelişim isteyen kişiler bu konuyu sıkça kullanmaktadır. Ferforjeler ile ilgili en önemli eserler 1700’lü yıllarda Fransızlar tarafından ortaya konulmuştur. Geçmişi çok <extra_id_13>ye dayanan ferforjeler <extra_id_14> ülkemizde de yaygın bir şekilde kullanılmaktadır. “Ferforje” konusunda kullanılan demirin kaliteli olması önemlidir. Aynı şekilde bu demire <extra_id_15> için ustalık <extra_id_16> konuda öncelikle kesim, <extra_id_17> delme işlemleri yapılmaktadır. Sonrasında ise kıvırma, şekil verme, kelepçe takma ve kaynak işlemleri yapılmaktadır. En sonunda ise taşlama ve zımparalama işlemi yapılıp boyanarak ferforjeler hazır hale getirilmektedir. “Fer <extra_id_18> yapan firmalar, her türlü ihtiyaca cevap verecek donanımdadır. Özellikle <extra_id_19> da gelişmeler yaşanmış ve üretim süreleri <extra_id_20> da kısalmıştır. Böylece artan ihtiyaç kolayca karşılanmaktadır. “Ferforje <extra_id_21> ister iç cephede ister dış cephede kullanılsın, estetik olarak şık bir görüntü sunmaktadır. <extra_id_22>lerini bu yöntemle <extra_id_23> hale getirebilir, nostalji ile çağdaşlığı birleştirebilirsiniz. Yeşilay Genel Başkanı Prof. Dr. İhsan Karaman, alkollü içki ambalajları üzerinde sağlıkla ilgili uyarı mesajları konulması zorunluluğuna “evet ama <extra_id_24>diklerini belirtti. Bundan böyle içkilerin ambalajları üzerinde 18 yaş, araba kullanımı ve hamilelere ilişkin işaretli uyarılar ile “Alkol dostunuz değildir” yazılı uyarı <extra_id_25> yer alacağını belirten Karaman, uygulamanın kamu sağlığı için gerekli olduğunu vurguladı. <extra_id_26> önerilerinin çok geniş bir yelpaze\n",
      "--------------\n",
      "<extra_id_0> ettirmek <extra_id_1>otu <extra_id_2>, tarımından <extra_id_3> çok köklü ve <extra_id_4>nin insanları <extra_id_5> yaşayan <extra_id_6>in <extra_id_7> ve bir araya <extra_id_8> dedi <extra_id_9> hoşlanan kişiler tarafından <extra_id_10> korkuluğu gibi yerlerde faydalanılırken <extra_id_11> balkon korkuluğu gibi yerlerde faydalanılmaktadır. Bu konuda dikkat <extra_id_12>, <extra_id_13> eski <extra_id_14>, <extra_id_15> şekil vermek <extra_id_16>ta önemlidir. Bu <extra_id_17> büküm ve <extra_id_18>forje” konusunda imalat <extra_id_19> teknolojinin gelişmesi ile birlikte bu konuda <extra_id_20> daha <extra_id_21>” <extra_id_22> Sizler de evinizin belirli bölüm <extra_id_23> daha kullanışlı ve daha estetik bir <extra_id_24> yetmez” de <extra_id_25> mesajının <extra_id_26> Avrupa’da uyarı <extra_id_27>de ele alındığını\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 33\n",
    "inputs = json_lines[sample_idx]['inputs']\n",
    "targets = json_lines[sample_idx]['targets']\n",
    "\n",
    "print(inputs)\n",
    "print('--------------')\n",
    "print(targets)\n",
    "inputs_encoded = json_lines[sample_idx]['inputs_encoded']\n",
    "targets_encoded = json_lines[sample_idx]['targets_encoded']\n",
    "\n",
    "model_inputs = tf.keras.utils.pad_sequences([inputs_encoded], maxlen = 512, padding = 'post', truncating = 'post')\n",
    "model_inputs = torch.from_numpy(model_inputs).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7da98717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS> yani yani yani... yani... yani görülebilecek görülebilecek:<extra_id_95>: Ko: Kutu<extra_id_95>: Gurur<extra_id_95>; yani:<extra_id_95>:<extra_id_95>: yani: 1.<extra_id_95>: 1. G yani yani yani yani yani yani yani yani yani yani yani yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani...... yani... Çubuk: yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... Çubuk, yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani...\n"
     ]
    }
   ],
   "source": [
    "model_outputs = model.generate(inputs = model_inputs, max_length = 512, do_sample = False)\n",
    "model_output_as_list = model_outputs.numpy()[0].tolist()\n",
    "print(tokenizer.decode(model_output_as_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56d3aa9-61bd-4995-a377-431b1b3d8820",
   "metadata": {},
   "source": [
    "- Same input but instead of using the tokens provided in the json file, tokenize the text input via **VBARTTokenizer_T5_Sentinels** tokenizer and then infer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a8cfa89-25ba-4f98-ab02-e2332f9f7fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_encoded_vbart_tokenizer = tokenizer.encode(inputs)\n",
    "targets_encoded_vbart_tokenizer = tokenizer.encode(targets)\n",
    "\n",
    "model_inputs = tf.keras.utils.pad_sequences([inputs_encoded_vbart_tokenizer], maxlen = 512, padding = 'post', truncating = 'post')\n",
    "model_inputs = torch.from_numpy(model_inputs).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8e5e620-41d9-40e6-8c8f-24f284857de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS> yani yani yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani... yani...... yani...... yani...... yani...... yani...... yani...... yani...... yani... yani... yani... yani... yani...... yani...... yani...... yani...... yani...... yani...... yani...... yani...... yani...... yani... yani... yani... yani... yani...... yani...... yani...... yani...... yani...... yani...... yani... yani... yani... yani... yani...... yani...... yani...... yani...... yani...... yani...... yani... yani... yani... yani... yani...... yani...... yani...... yani...... yani...... yani...... yani... yani... yani... yani... yani...... yani...... yani...... yani...... yani...... yani...... yani... yani... yani... yani... yani...... yani...... yani...... yani...... yani...... yani...... yani... yani... yani... yani... yani...... yani...... yani...... yani...... yani...... yani... yani... yani... yani... yani...... yani...... yani...... yani...... yani...... yani... yani... yani... yani... yani...... yani...... yani...... yani...... yani...... yani... yani... yani... yani... yani...... yani...... yani...... yani...... yani...... yani... yani... yani... yani... yani...... yani...... yani...... yani...... yani...... yani...... yani... yani... yani... yani... yani...... yani...... yani...... yani...... yani...... yani... yani... yani... yani... yani...... yani...... yani...... yani...... yani...... yani...... yani... yani... yani... yani... yani...... yani...... yani...... yani...... yani...... yani...... yani... yani... yani... yani... yani...... yani...... yani...... yani...... yani...... yani...... yani... yani... yani... yani... yani...... yani...... yani...... yani...... yani...... yani...... yani... yani... yani... yani... yani...... yani...... yani...\n"
     ]
    }
   ],
   "source": [
    "model_outputs = model.generate(inputs = model_inputs, max_length = 512, do_sample = False)\n",
    "model_output_as_list = model_outputs.numpy()[0].tolist()\n",
    "print(tokenizer.decode(model_output_as_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f146bad0-252b-4ee4-a8dc-0ed330f3e3e4",
   "metadata": {},
   "source": [
    "- Infer with custom text input. Using samples from **pretrain_oscarmc4_cleaned_hf_dataset-predict.txt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a63400e-2ca6-4db4-a7d8-a6ef2f5f176c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1 = \"[NLG] G <extra_id_0> katılımıyla yedi sayısına <extra_id_1>. Bir yıl sonra AB de toplantılara katılmaya başlamış, G <extra_id_2> adı yine yedi rakamıyla birlikte anılmakta <extra_id_3> zirvede Trump konuyu gündeme getirmişti <extra_id_4> Bu yıl da gündeme getirdiği, İngiltere, Almanya, Kanada ve <extra_id_5>nın itirazlarına rağmen 2020 <extra_id_6> katılımcılar arasında <extra_id_7>işim açısından <extra_id_8> Sorular çözülmese <extra_id_9> planlı ve plansız toplantıların da sorunların yönetimine ve çözümüne katkıda bulunduğunu unutmamakta <extra_id_10> var. 24-26 Ağustos’ta Fransa’nın Biarritz kentinde düzenlenen bu yılki zirvede de pek <extra_id_11> masaya yatır <extra_id_12> savaşları, küresel ısınma, uluslararası güvenlik, İran ve Amazon ormanlarındaki yangınlar farklı oturumlarda <extra_id_13> alındı. <extra_id_14> sorunu henüz çözülmedi ancak Trump’ın açıklamalarının tonu değişti. Cumhurbaşkanı Ruhani ile <extra_id_15> olgunlaşırsa <extra_id_16>’ın şartlardan ne kast ettiği, dönüş yolunda ya da <extra_id_17> fikrini değiştirip değiştirmeyeceği tabii ki bilinmiyor <extra_id_18> Her an her şey olabilir, Trump <extra_id_19> yaptırım paketini uygulamaya koyup Zarif ve Ruhani’nin manevra alanını daraltmayı da deneyebilir. İran <extra_id_20> nihayetinde bizim üstümüze de yük oluyor. <extra_id_21> başka önemli konu da Amerika’nın Rusya’yı yeniden G7 platformuna dahil <extra_id_22>, diğer komşumuz <extra_id_23> konuşabilecekleri zeminlerin sayısının artması Türkiye’nin genel olarak lehine. Diğer yandan bu yakınlaşmanın Suriye’de kurduğumuz zor denklemleri etkileme potansiyeli taşıdığını da görmezden <extra_id_24> Amerika-Rusya yakınlaşması dünyadaki gerginliği <extra_id_25> olduğunda Türkiye’nin çıkar ve beklentilerini dikkate almayan bir <extra_id_26> büyük devlet uzlaşmaları çok yaşandı. <extra_id_27> G7 Zirvesi’nden çıkartması gereken bir başka sonuç ise <extra_id_28>’nin <extra_id_29> kabul ettiği Trablus Hükümeti üstündeki baskı <extra_id_30> Zirve Deklarasyonunda da zaten Libya için tüm tarafları <extra_id_31> bir uluslararası konferans çağrısı yapıldı ve Afrika Birliği <extra_id_32>lendiği vurgulandı. <extra_id_33>k <extra_id_34> var ama onların yorumu iktisatçıların alanına giriyor. <extra_id_35> kaydedilir ve <extra_id_36> engeller kalkar. Trump’ın açıklaması, yorumlar ve analizler olumlu yönde. Çin’le <extra_id_37>ebileceğini varsaymakta yarar var diye <extra_id_38> ö <extra_id_39>. O zaman ona göre bir planlama yapmam gerekir... Buna ekstra olarak bir şirket üzerinden <extra_id_40>niz gerekir vergi <extra_id_41>le sizin uğraşmanız eğer acemi <extra_id_42>. Bu <extra_id_43> aynı motorunu 2 <extra_id_44> alım <extra_id_45> iş değişir... Diyelim almanyada tanıdığın var. B <extra_id_46> misal. Türkiye vatandaşı ise, <extra_id_47>la türkiyeye gelir. belli <extra_id_48>. 6 ayda bir yurt dışına çıkması gerekir motorun. Ama gene ucuza mal etmiş <extra_id_49>san <extra_id_50>sin... Bu bilgiler benim 3 <extra_id_51>dir. Yasalarda ve yürütme de değişiklik oldu ise affola... bu <extra_id_52> değiştimi acaba. kıbrıstan araba getiril <extra_id_53>liyordu ama <extra_id_54> biliyorum <extra_id_55>cam\"\n",
    "sample_2 = \"[NLU] G7, yani Yediler Grubu dünyanın en gelişmiş yedi ekonomisini bünyesinde barındıran <extra_id_0> ilk kez 1973’de düşünülmüş, dört üye diye başlanmış ama çok geçmeden sayı altıya çıkmış, 1976’da <extra_id_1>nın katılımıyla yedi sayısına ulaşılmış. Bir yıl sonra AB de toplantılara katılmaya başlamış, G8 haline 1997 yılından sonra Rusya Federasyonu’ <extra_id_2> üstüne üye olarak katılımıyla dönüşmüş. Kırım’ın işgali yüzünden Rusya’nın dışlanmasıyla 2014’den bu yana grubun adı yine yedi rakamı <extra_id_3> anılmakta <extra_id_4> Kanada’da düzenlenen olaylı zirvede Trump konuyu gündeme getirmişti. Bu yıl <extra_id_5> getirdiği, İngiltere, Almanya, Kanada ve Fransa’nın itirazlarına rağmen 2020 zirvesinde Putin’i katılımcılar <extra_id_6> olacağı söyleniyor. Ki bu da küresel yönetişim açısından önemli. Sorular çözülmese <extra_id_7>lerin ve <extra_id_8> planlı ve <extra_id_9>sız toplantıların da sorunların yönetimine ve çözümüne katkıda bulunduğunu <extra_id_10>. 24-26 Ağustos’ta Fransa’nın Biarritz kentinde düzenlenen bu yılki zirvede de pek çok küresel sorun masaya yatırıldı. Resmi <extra_id_11> olan toplantıda ticaret savaşları, küresel ısınma, uluslararası güvenlik <extra_id_12> ve Amazon ormanlarındaki yangınlar farklı oturumlarda ele alındı. İran da belli ki sesini duyurabildi. <extra_id_13>di ancak Trump’ın açıklamalarının tonu <extra_id_14>. Cumhurbaşkanı Ruhani ile şartlar olgunlaşırsa buluşabileceğini söyledi. Trump’ın şartlardan ne kast ettiği, dönüş yolunda ya da gelecek <extra_id_15>yeceği tabii ki bilinmiyor. Her an her şey <extra_id_16>, Trump ve yönetimi her şeyi yapabilir. Yeni bir yaptırım paketini uygulamaya koyup Zarif ve Ruhani <extra_id_17> daraltmayı da deneyebilir. İran’a uygulanan yaptırımlar nihayetinde bizim üstümüze de yük oluyor. Bir başka önemli konu da Amerika’nın Rusya’yı yeniden G7 platformuna <extra_id_18> Biri müttefik <extra_id_19> İki büyük ülkenin yakınlaşması, sorunlarını konuşabilecekleri zeminlerin sayısının artması Türkiye’nin genel olarak lehine. Diğer yandan bu yakınlaşmanın Suriye’de kurduğumuz zor denklemleri etkileme potansiyeli taşıdığını da görmezden gelemeyiz. Amerika-Rusya yakınlaşması dünyadaki gerginliğin ve çatışma risklerinin azaltılmasına yardımcı <extra_id_20> Suriye söz konusu olduğunda Türkiye’ <extra_id_21> çıkar ve beklentilerini dikkate <extra_id_22> bir uzlaşmaya var <extra_id_23> yol açabilir. Ne de olsa <extra_id_24> “quid pro quo” olarak adlandırılan bu tür büyük devlet uzlaşmaları çok yaşandı. Türkiye’ <extra_id_25> çıkartması gereken bir başka sonuç ise Libya’da çözüm için taraflar <extra_id_26> daha doğrusu Türkiye’nin desteklediği, BM’in meşru kabul ettiği Trablus Hükümeti üstündeki baskının artma olasılığının yükseldiği. Zirve Deklarasyonunda da zaten Libya için tüm tarafları ve bölgesel aktörleri kapsayan bir uluslararası konferans çağrısı yapıldı ve Afrika Birliği ile BM’nin çabalarının desteklendiği\"\n",
    "sample_3 = \"[NLU] az 3 harf girerek arama yapabilirsiniz. Kitaplarında bir samimiyet ve sahicilik var. Kimi zaman anlatıcı ile sohbet ediyormuşum <extra_id_0>. Yazarken karşında okur olarak tahayyül ettiğin hayali ya da gerçek birileri var mı? Böyle <extra_id_1>ne sevindim, gerçi ben yazarken doğruyu söylediğimi hissetmiyorum. Yalan söylediğimi de hissetmiyorum. Belki bir çeşit kaygan gerçekliğe ilerliyorum ama bu hiçbir zaman bitmeyen bir sürecin parçası. Yazarken okurları pek düşünmüyorum. Her zaman yazdıklarımın kontrolünü kaybedeceğim bir noktaya varmak istiyorum. Metnin kendi <extra_id_2>nı <extra_id_3> Bazı yazarlar <extra_id_4> da <extra_id_5> yazmaya eğilimliyken, bazıları da uzun soluklu romanlarla kendilerini daha rahat ifade edebiliyor. Sence bunun beynimizin bilişsel işlevleri ya da ayarlarıyla bir ilgisi var mı? Yazacağın metnin biçimini önceden planlar mısın <extra_id_6> mı bırakır <extra_id_7> böyle düşünmemiştim. Şu anda uzun bir romanı yarıladım, o zaman belki beynime zıt yönde çalışıyorum! Herkes bir romanın nasıl olması gerektiği hakkında konuşuyor ama ben kitabın kendi kurallarını koyduğuna <extra_id_8> yontmak gibi. Büyük bir kayan var ve içinde gizlenmiş bir kitabın, yazmak ise onu bulmak <extra_id_9> Tek veya birden fazla <extra_id_10> ile başlıyorum. Çok fazla taslak yazıyorum. Kitap yazdığımı unutmaya çalışıyorum. Son kitabın Multiple Choice’u 1993 <extra_id_11> Şili’de girdiğin çoktan seçmeli üniversite sınavının biçiminde kurgulamışsın. Okur metni anlamlandırma sürecine <extra_id_12> dâhil oluyor, aynı zamanda yaratıcı düşünceyi körelten eğitim sistemiyle dalga geçiyorsun. Testin yaratıcı bir edebi <extra_id_13>ya dönüşmesi epey ironik. Deneysel edebiyatın yayıncılık sektöründeki kabulünde, okuldaki geleneksel hocalarımızın şüpheciliği ve direncine benzer bir durum var mı sence? Ama bu normal, bütün <extra_id_14>. Şunu belirtmeliyim ki, deneysel edebiyat olarak algılanılacak bir şey yazmak için uğraşmıyordum. Sadece anlatmaya çalıştığım şeyin o biçimde anlatılması gerektiğine ikna oldum. Edebiyat <extra_id_15> zorlar <extra_id_16> daha tuhaftır ama Multiple Choice önceki kitaplarımdan daha deneyselmiş gibi hissetmiyorum. Öyle gözüküyor ama benim <extra_id_17> değil. Kitabı, kapağındaki test sorusundan da anlaşıldığı gibi, <extra_id_18>ye koyamıyoruz, hepsinden birer parça barındırıyor. Edebi türler <extra_id_19>? <extra_id_20> her zaman bulanık <extra_id_21>. Edebiyat tarihi bundan ibaret. Kitap pazarı sınırları <extra_id_22> kitaplara ürün gibi davranıyor ama eminim ki okurlar bunu düşünmüyor. Edebi türler etikettir veya kılavuz niteliği taşır ama her iyi kitap buna karşı koyar. Büyülü Dağ’ı okuduktan <extra_id_23> ‘ <extra_id_24>, bu bir roman’ <extra_id_25>dim. Sadece bütünlüklü ve anlamlı bir deneyim olduğunu <extra_id_26> Bence edebi türler, giydiğin ama bir türlü rahat edemediğin gömlekler gibi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06392c33-5397-42ab-a3cc-7a764b6bf7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS> yani görülebilecek: görülebilecek: G:: G yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani... yani yani... yani... yani... yani... yani... yani... yani... yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani... yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani... yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani yani... yani\n",
      "---------------------------------------------------\n",
      "<BOS> yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek yani görülebilecek yani görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek yani görülebilecek yani görülebilecek yani görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek yani görülebilecek yani görülebilecek yani görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek yani görülebilecek yani görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek yani görülebilecek yani görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek\n",
      "---------------------------------------------------\n",
      "<BOS> yani görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek görülebilecek yani... yani... yani... yani... Sadece... Sadece... Sadece... Sadece... Sadece... Sadece... Sadece... Sadece: Sadece: Sadece Sadece: Sadece Sadece: Sadece Sadece: Sadece Ko: Yani. Sadece Ko. yani... Sadece... yani... Sadece... yani: Ko. İnsanlar yani. Ko. Ko. Ko. Ko. Ko. yani yani yani yani yani yani yani yani yani yani yani... yani... yani... yani... yani... yani... Sadece... yani: Ko. Ko. Ko. Ko. Ko. Ko. Ko. Ko. Ko. Sadece... yani yani yani yani... Sadece yani yani yani. Sadece... yani. Sadece... yani. Ko. Ko. Ko. Ko. Ko. Ko. Ko. Ko. Ko. Ko. yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani... yani yani Yazar İnsanları<extra_id_96> yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani Yazar İnsanları<extra_id_96> yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani Yazar İnsanları<extra_id_96> yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani yani\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for sample in [sample_1, sample_2, sample_3]:\n",
    "    inputs_encoded_vbart_tokenizer = tokenizer.encode(sample)\n",
    "    \n",
    "    model_inputs = tf.keras.utils.pad_sequences([inputs_encoded_vbart_tokenizer], maxlen = 512, padding = 'post', truncating = 'post')\n",
    "    model_inputs = torch.from_numpy(model_inputs).to(device)\n",
    "\n",
    "    model_outputs = model.generate(inputs = model_inputs, max_length = 512, do_sample = False)\n",
    "    model_output_as_list = model_outputs.numpy()[0].tolist()\n",
    "    print(tokenizer.decode(model_output_as_list))\n",
    "    print('---------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb6f9db-5da6-4d14-b2e7-ff516e73fd10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
